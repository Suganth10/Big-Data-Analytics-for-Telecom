{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download() - to install components of nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Normally used terms\n",
    "\n",
    "#Corpus - Body of text. Corpora is a collection of texts, journals \n",
    "\n",
    "#Lexicon - Words and their meanings. Based on the area the first meaning varies.\n",
    "#eg : Bull for a financial investor refers to someone who is interested in market whereas in english \n",
    "#bull refers to an animal \n",
    "\n",
    "#token - refers to an entity which is split based on rules from a particular thing. \n",
    "#Like word tokenize from a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Tokenization\n",
    "\n",
    "sen = \"I am going for a run. I will be running very fast as this run should be made as ran not even ran actually running is the word \"\n",
    "\n",
    "lists = word_tokenize(sen)\n",
    "print(lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Stop words \n",
    "# In NLP useless words are referred to as stopwords. i.e words which doesnt convey any meaning \n",
    "#eg: very,having,ourseleves,is,was etc\n",
    "\n",
    "# These words can be eliminated when we are analyzing the text data as they dont convey any meaning\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#stemming the words\n",
    "#The reason why we stem is to shorten the lookup, and normalize sentences.\n",
    "\n",
    "ps = PorterStemmer() #Stemming the words - run,running both refer to run except the tense.\n",
    "#example \n",
    "print(ps.stem('Pythoning'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example_words = [\"python\",\"pythoner\",\"pythoning\",\"pythoned\",\"pythonly\"]\n",
    "for w in example_words:\n",
    "    print(ps.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#POS - Parts of Speech Tags  - i.e labelling words in a sentence as nouns,adjs,verbs etc..\n",
    "\n",
    "\n",
    "# POS tag list:\n",
    "\n",
    "# CC\tcoordinating conjunction\n",
    "# CD\tcardinal digit\n",
    "# DT\tdeterminer\n",
    "# EX\texistential there (like: \"there is\" ... think of it like \"there exists\")\n",
    "# FW\tforeign word\n",
    "# IN\tpreposition/subordinating conjunction\n",
    "# JJ\tadjective\t'big'\n",
    "# JJR\tadjective, comparative\t'bigger'\n",
    "# JJS\tadjective, superlative\t'biggest'\n",
    "# LS\tlist marker\t1)\n",
    "# MD\tmodal\tcould, will\n",
    "# NN\tnoun, singular 'desk'\n",
    "# NNS\tnoun plural\t'desks'\n",
    "# NNP\tproper noun, singular\t'Harrison'\n",
    "# NNPS\tproper noun, plural\t'Americans'\n",
    "# PDT\tpredeterminer\t'all the kids'\n",
    "# POS\tpossessive ending\tparent's\n",
    "# PRP\tpersonal pronoun\tI, he, she\n",
    "# PRP$\tpossessive pronoun\tmy, his, hers\n",
    "# RB\tadverb\tvery, silently,\n",
    "# RBR\tadverb, comparative\tbetter\n",
    "# RBS\tadverb, superlative\tbest\n",
    "# RP\tparticle\tgive up\n",
    "# TO\tto\tgo 'to' the store.\n",
    "# UH\tinterjection\terrrrrrrrm\n",
    "# VB\tverb, base form\ttake\n",
    "# VBD\tverb, past tense\ttook\n",
    "# VBG\tverb, gerund/present participle\ttaking\n",
    "# VBN\tverb, past participle\ttaken\n",
    "# VBP\tverb, sing. present, non-3d\ttake\n",
    "# VBZ\tverb, 3rd person sing. present\ttakes\n",
    "# WDT\twh-determiner\twhich\n",
    "# WP\twh-pronoun\twho, what\n",
    "# WP$\tpossessive wh-pronoun\twhose\n",
    "# WRB\twh-abverb\twhere, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize,PunktSentenceTokenizer\n",
    "from nltk.corpus import state_union #It has president speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state_union.raw(\"2005-GWBUSH.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent_tokenize(state_union.raw(\"2005-GWBUSH.txt\"))[:5] # First five sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new = PunktSentenceTokenizer() #Unsupervised Machine learning tokenizer(It can be trained too)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent = new.tokenize(state_union.raw(\"2005-GWBUSH.txt\"))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Chunking is a concept where we group in words into meaningful chunks. mainly to group words which are in relation\n",
    "# to the noun - Regular expressions are used to achieve this \n",
    "for i in sent:\n",
    "    words = word_tokenize(i);\n",
    "    tags = nltk.pos_tag(words);\n",
    "    chunkgram = r\"\"\"chunk:{<RB.?>*<NNP>+<NN>?}\"\"\"\n",
    "    parser = nltk.RegexpParser(chunkgram)\n",
    "    chunked = parser.parse(tags)\n",
    "    print(chunked)\n",
    "    #chunked.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for subtree in chunked.subtrees():\n",
    "    print(subtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to print subtrees with label chunk we provided.\n",
    "for subtree in chunked.subtrees(filter=lambda t:t.label()=='chunk'):\n",
    "    print(subtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Chinking is used if we have to remove some chunks from the created chunks\n",
    "for i in sent:\n",
    "    words = word_tokenize(i);\n",
    "    tags = nltk.pos_tag(words);\n",
    "    chunkgram = r\"\"\"chunk:{<RB.?>*<NNP>+<NN>?}\n",
    "                        }<VB.?|IN|DT>+{\"\"\"\n",
    "    parser = nltk.RegexpParser(chunkgram)\n",
    "    chunked = parser.parse(tags)\n",
    "    print(chunked)\n",
    "    chunked.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Named entity recognition\n",
    "#The idea is to have the machine immediately\n",
    "#be able to pull out \"entities\" like people, places, things, locations, monetary figures, and more.\n",
    "\n",
    "# ORGANIZATION - Georgia-Pacific Corp., WHO\n",
    "# PERSON - Eddy Bonte, President Obama\n",
    "# LOCATION - Murray River, Mount Everest\n",
    "# DATE - June, 2008-06-29\n",
    "# TIME - two fifty a m, 1:30 p.m.\n",
    "# MONEY - 175 million Canadian Dollars, GBP 10.40\n",
    "# PERCENT - twenty pct, 18.75 %\n",
    "# FACILITY - Washington Monument, Stonehenge\n",
    "# GPE - South East Asia, Midlothian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in sent:\n",
    "    words = word_tokenize(i);\n",
    "    tags = nltk.pos_tag(words);\n",
    "    chunked = nltk.ne_chunk(tags)\n",
    "    print(chunked)\n",
    "    chunked.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Lemmatizing in NLTK\n",
    "#A very similar operation to stemming. The major difference is stemming can often create non-existent\n",
    "#words, whereas lemmas are actual words.\n",
    "#your root stem(from stemming), meaning the word you end up with, is not something you can just\n",
    "#look up in a dictionary, but you can look up a lemma(after lemmetizing)\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "print(lemmatizer.lemmatize(\"cats\"))\n",
    "print(lemmatizer.lemmatize(\"cacti\"))\n",
    "print(lemmatizer.lemmatize(\"geese\"))\n",
    "print(lemmatizer.lemmatize(\"rocks\"))\n",
    "print(lemmatizer.lemmatize(\"python\"))\n",
    "print(lemmatizer.lemmatize(\"better\", pos=\"a\"))\n",
    "print(lemmatizer.lemmatize(\"best\", pos=\"a\"))\n",
    "print(lemmatizer.lemmatize(\"run\"))\n",
    "print(lemmatizer.lemmatize(\"run\",'v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Accessing corpora data folder.. In windows goto Appdata folder and check for it.\n",
    "#print(nltk.__file__) -- In this location find data file and check the path.\n",
    "from nltk.corpus import nps_chat\n",
    "data = nps_chat.xml(\"10-19-adults_706posts.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Wordnet - Important corpora - FOr checking synonyms, Antonyms, Similarity of words\n",
    "from nltk.corpus import wordnet\n",
    "syn = wordnet.synsets(\"best\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#synonyms\n",
    "synonyms = []\n",
    "for l in syn:\n",
    "    for f in l.lemmas():\n",
    "        synonyms.append(f.name())\n",
    "        \n",
    "print(synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#similarity \n",
    "a1 = wordnet.synset(\"well.n.01\") # n refers to noun here- use lemmas to find similarity\n",
    "a2 = wordnet.synset(\"best.n.02\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Example to workon -- Movie reviews\n",
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "document = []\n",
    "for category in movie_reviews.categories():\n",
    "    for fileids in movie_reviews.fileids(category):\n",
    "        document.append((movie_reviews.words(fileids),category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = movie_reviews.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all_words=[w for w in words if w not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_words = [w.lower() for w in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_words = [ w for w in all_words if w not in string.punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_words = nltk.FreqDist(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = list(final_words.keys())[:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['plot',\n",
       " 'two',\n",
       " 'teen',\n",
       " 'couples',\n",
       " 'go',\n",
       " 'to',\n",
       " 'a',\n",
       " 'church',\n",
       " 'party',\n",
       " 'drink',\n",
       " 'and',\n",
       " 'then',\n",
       " 'drive',\n",
       " 'they',\n",
       " 'get',\n",
       " 'into',\n",
       " 'an',\n",
       " 'accident',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'guys',\n",
       " 'dies',\n",
       " 'but',\n",
       " 'his',\n",
       " 'girlfriend',\n",
       " 'continues',\n",
       " 'see',\n",
       " 'him',\n",
       " 'in',\n",
       " 'her',\n",
       " 'life',\n",
       " 'has',\n",
       " 'nightmares',\n",
       " 'what',\n",
       " 's',\n",
       " 'deal',\n",
       " 'watch',\n",
       " 'movie',\n",
       " 'sorta',\n",
       " 'find',\n",
       " 'out',\n",
       " 'critique',\n",
       " 'mind',\n",
       " 'fuck',\n",
       " 'for',\n",
       " 'generation',\n",
       " 'that',\n",
       " 'touches',\n",
       " 'on',\n",
       " 'very',\n",
       " 'cool',\n",
       " 'idea',\n",
       " 'presents',\n",
       " 'it',\n",
       " 'bad',\n",
       " 'package',\n",
       " 'which',\n",
       " 'is',\n",
       " 'makes',\n",
       " 'this',\n",
       " 'review',\n",
       " 'even',\n",
       " 'harder',\n",
       " 'write',\n",
       " 'since',\n",
       " 'i',\n",
       " 'generally',\n",
       " 'applaud',\n",
       " 'films',\n",
       " 'attempt',\n",
       " 'break',\n",
       " 'mold',\n",
       " 'mess',\n",
       " 'with',\n",
       " 'your',\n",
       " 'head',\n",
       " 'such',\n",
       " 'lost',\n",
       " 'highway',\n",
       " 'memento',\n",
       " 'there',\n",
       " 'are',\n",
       " 'good',\n",
       " 'ways',\n",
       " 'making',\n",
       " 'all',\n",
       " 'types',\n",
       " 'these',\n",
       " 'folks',\n",
       " 'just',\n",
       " 'didn',\n",
       " 't',\n",
       " 'snag',\n",
       " 'correctly',\n",
       " 'seem',\n",
       " 'have',\n",
       " 'taken',\n",
       " 'pretty',\n",
       " 'neat',\n",
       " 'concept',\n",
       " 'executed',\n",
       " 'terribly',\n",
       " 'so',\n",
       " 'problems',\n",
       " 'well',\n",
       " 'its',\n",
       " 'main',\n",
       " 'problem',\n",
       " 'simply',\n",
       " 'too',\n",
       " 'jumbled',\n",
       " 'starts',\n",
       " 'off',\n",
       " 'normal',\n",
       " 'downshifts',\n",
       " 'fantasy',\n",
       " 'world',\n",
       " 'you',\n",
       " 'as',\n",
       " 'audience',\n",
       " 'member',\n",
       " 'no',\n",
       " 'going',\n",
       " 'dreams',\n",
       " 'characters',\n",
       " 'coming',\n",
       " 'back',\n",
       " 'from',\n",
       " 'dead',\n",
       " 'others',\n",
       " 'who',\n",
       " 'look',\n",
       " 'like',\n",
       " 'strange',\n",
       " 'apparitions',\n",
       " 'disappearances',\n",
       " 'looooot',\n",
       " 'chase',\n",
       " 'scenes',\n",
       " 'tons',\n",
       " 'weird',\n",
       " 'things',\n",
       " 'happen',\n",
       " 'most',\n",
       " 'not',\n",
       " 'explained',\n",
       " 'now',\n",
       " 'personally',\n",
       " 'don',\n",
       " 'trying',\n",
       " 'unravel',\n",
       " 'film',\n",
       " 'every',\n",
       " 'when',\n",
       " 'does',\n",
       " 'give',\n",
       " 'me',\n",
       " 'same',\n",
       " 'clue',\n",
       " 'over',\n",
       " 'again',\n",
       " 'kind',\n",
       " 'fed',\n",
       " 'up',\n",
       " 'after',\n",
       " 'while',\n",
       " 'biggest',\n",
       " 'obviously',\n",
       " 'got',\n",
       " 'big',\n",
       " 'secret',\n",
       " 'hide',\n",
       " 'seems',\n",
       " 'want',\n",
       " 'completely',\n",
       " 'until',\n",
       " 'final',\n",
       " 'five',\n",
       " 'minutes',\n",
       " 'do',\n",
       " 'make',\n",
       " 'entertaining',\n",
       " 'thrilling',\n",
       " 'or',\n",
       " 'engaging',\n",
       " 'meantime',\n",
       " 'really',\n",
       " 'sad',\n",
       " 'part',\n",
       " 'arrow',\n",
       " 'both',\n",
       " 'dig',\n",
       " 'flicks',\n",
       " 'we',\n",
       " 'actually',\n",
       " 'figured',\n",
       " 'by',\n",
       " 'half',\n",
       " 'way',\n",
       " 'point',\n",
       " 'strangeness',\n",
       " 'did',\n",
       " 'start',\n",
       " 'little',\n",
       " 'bit',\n",
       " 'sense',\n",
       " 'still',\n",
       " 'more',\n",
       " 'guess',\n",
       " 'bottom',\n",
       " 'line',\n",
       " 'movies',\n",
       " 'should',\n",
       " 'always',\n",
       " 'sure',\n",
       " 'before',\n",
       " 'given',\n",
       " 'password',\n",
       " 'enter',\n",
       " 'understanding',\n",
       " 'mean',\n",
       " 'showing',\n",
       " 'melissa',\n",
       " 'sagemiller',\n",
       " 'running',\n",
       " 'away',\n",
       " 'visions',\n",
       " 'about',\n",
       " '20',\n",
       " 'throughout',\n",
       " 'plain',\n",
       " 'lazy',\n",
       " 'okay',\n",
       " 'people',\n",
       " 'chasing',\n",
       " 'know',\n",
       " 'need',\n",
       " 'how',\n",
       " 'giving',\n",
       " 'us',\n",
       " 'different',\n",
       " 'offering',\n",
       " 'further',\n",
       " 'insight',\n",
       " 'down',\n",
       " 'apparently',\n",
       " 'studio',\n",
       " 'took',\n",
       " 'director',\n",
       " 'chopped',\n",
       " 'themselves',\n",
       " 'shows',\n",
       " 'might',\n",
       " 've',\n",
       " 'been',\n",
       " 'decent',\n",
       " 'here',\n",
       " 'somewhere',\n",
       " 'suits',\n",
       " 'decided',\n",
       " 'turning',\n",
       " 'music',\n",
       " 'video',\n",
       " 'edge',\n",
       " 'would',\n",
       " 'actors',\n",
       " 'although',\n",
       " 'wes',\n",
       " 'bentley',\n",
       " 'seemed',\n",
       " 'be',\n",
       " 'playing',\n",
       " 'exact',\n",
       " 'character',\n",
       " 'he',\n",
       " 'american',\n",
       " 'beauty',\n",
       " 'only',\n",
       " 'new',\n",
       " 'neighborhood',\n",
       " 'my',\n",
       " 'kudos',\n",
       " 'holds',\n",
       " 'own',\n",
       " 'entire',\n",
       " 'feeling',\n",
       " 'unraveling',\n",
       " 'overall',\n",
       " 'doesn',\n",
       " 'stick',\n",
       " 'because',\n",
       " 'entertain',\n",
       " 'confusing',\n",
       " 'rarely',\n",
       " 'excites',\n",
       " 'feels',\n",
       " 'redundant',\n",
       " 'runtime',\n",
       " 'despite',\n",
       " 'ending',\n",
       " 'explanation',\n",
       " 'craziness',\n",
       " 'came',\n",
       " 'oh',\n",
       " 'horror',\n",
       " 'slasher',\n",
       " 'flick',\n",
       " 'packaged',\n",
       " 'someone',\n",
       " 'assuming',\n",
       " 'genre',\n",
       " 'hot',\n",
       " 'kids',\n",
       " 'also',\n",
       " 'wrapped',\n",
       " 'production',\n",
       " 'years',\n",
       " 'ago',\n",
       " 'sitting',\n",
       " 'shelves',\n",
       " 'ever',\n",
       " 'whatever',\n",
       " 'skip',\n",
       " 'where',\n",
       " 'joblo',\n",
       " 'nightmare',\n",
       " 'elm',\n",
       " 'street',\n",
       " '3',\n",
       " '7',\n",
       " '10',\n",
       " 'blair',\n",
       " 'witch',\n",
       " '2',\n",
       " 'crow',\n",
       " '9',\n",
       " 'salvation',\n",
       " '4',\n",
       " 'stir',\n",
       " 'echoes',\n",
       " '8',\n",
       " 'happy',\n",
       " 'bastard',\n",
       " 'quick',\n",
       " 'damn',\n",
       " 'y2k',\n",
       " 'bug',\n",
       " 'starring',\n",
       " 'jamie',\n",
       " 'lee',\n",
       " 'curtis',\n",
       " 'another',\n",
       " 'baldwin',\n",
       " 'brother',\n",
       " 'william',\n",
       " 'time',\n",
       " 'story',\n",
       " 'regarding',\n",
       " 'crew',\n",
       " 'tugboat',\n",
       " 'comes',\n",
       " 'across',\n",
       " 'deserted',\n",
       " 'russian',\n",
       " 'tech',\n",
       " 'ship',\n",
       " 'kick',\n",
       " 'power',\n",
       " 'within',\n",
       " 'gore',\n",
       " 'bringing',\n",
       " 'few',\n",
       " 'action',\n",
       " 'sequences',\n",
       " 'virus',\n",
       " 'empty',\n",
       " 'flash',\n",
       " 'substance',\n",
       " 'why',\n",
       " 'was',\n",
       " 'middle',\n",
       " 'nowhere',\n",
       " 'origin',\n",
       " 'pink',\n",
       " 'flashy',\n",
       " 'thing',\n",
       " 'hit',\n",
       " 'mir',\n",
       " 'course',\n",
       " 'donald',\n",
       " 'sutherland',\n",
       " 'stumbling',\n",
       " 'around',\n",
       " 'drunkenly',\n",
       " 'hey',\n",
       " 'let',\n",
       " 'some',\n",
       " 'robots',\n",
       " 'acting',\n",
       " 'below',\n",
       " 'average',\n",
       " 'likes',\n",
       " 're',\n",
       " 'likely',\n",
       " 'work',\n",
       " 'halloween',\n",
       " 'h20',\n",
       " 'wasted',\n",
       " 'real',\n",
       " 'star',\n",
       " 'stan',\n",
       " 'winston',\n",
       " 'robot',\n",
       " 'design',\n",
       " 'schnazzy',\n",
       " 'cgi',\n",
       " 'occasional',\n",
       " 'shot',\n",
       " 'picking',\n",
       " 'brain',\n",
       " 'if',\n",
       " 'body',\n",
       " 'parts',\n",
       " 'turn',\n",
       " 'otherwise',\n",
       " 'much',\n",
       " 'sunken',\n",
       " 'jaded',\n",
       " 'viewer',\n",
       " 'thankful',\n",
       " 'invention',\n",
       " 'timex',\n",
       " 'indiglo',\n",
       " 'based',\n",
       " 'late',\n",
       " '1960',\n",
       " 'television',\n",
       " 'show',\n",
       " 'name',\n",
       " 'mod',\n",
       " 'squad',\n",
       " 'tells',\n",
       " 'tale',\n",
       " 'three',\n",
       " 'reformed',\n",
       " 'criminals',\n",
       " 'under',\n",
       " 'employ',\n",
       " 'police',\n",
       " 'undercover',\n",
       " 'however',\n",
       " 'wrong',\n",
       " 'evidence',\n",
       " 'gets',\n",
       " 'stolen',\n",
       " 'immediately',\n",
       " 'suspicion',\n",
       " 'ads',\n",
       " 'cuts',\n",
       " 'claire',\n",
       " 'dane',\n",
       " 'nice',\n",
       " 'hair',\n",
       " 'cute',\n",
       " 'outfits',\n",
       " 'car',\n",
       " 'chases',\n",
       " 'stuff',\n",
       " 'blowing',\n",
       " 'sounds',\n",
       " 'first',\n",
       " 'fifteen',\n",
       " 'quickly',\n",
       " 'becomes',\n",
       " 'apparent',\n",
       " 'certainly',\n",
       " 'slick',\n",
       " 'looking',\n",
       " 'complete',\n",
       " 'costumes',\n",
       " 'isn',\n",
       " 'enough',\n",
       " 'best',\n",
       " 'described',\n",
       " 'cross',\n",
       " 'between',\n",
       " 'hour',\n",
       " 'long',\n",
       " 'cop',\n",
       " 'stretched',\n",
       " 'span',\n",
       " 'single',\n",
       " 'clich',\n",
       " 'matter',\n",
       " 'elements',\n",
       " 'recycled',\n",
       " 'everything',\n",
       " 'already',\n",
       " 'seen',\n",
       " 'nothing',\n",
       " 'spectacular',\n",
       " 'sometimes',\n",
       " 'bordering',\n",
       " 'wooden',\n",
       " 'danes',\n",
       " 'omar',\n",
       " 'epps',\n",
       " 'deliver',\n",
       " 'their',\n",
       " 'lines',\n",
       " 'bored',\n",
       " 'transfers',\n",
       " 'onto',\n",
       " 'escape',\n",
       " 'relatively',\n",
       " 'unscathed',\n",
       " 'giovanni',\n",
       " 'ribisi',\n",
       " 'plays',\n",
       " 'resident',\n",
       " 'crazy',\n",
       " 'man',\n",
       " 'ultimately',\n",
       " 'being',\n",
       " 'worth',\n",
       " 'watching',\n",
       " 'unfortunately',\n",
       " 'save',\n",
       " 'convoluted',\n",
       " 'apart',\n",
       " 'occupying',\n",
       " 'screen',\n",
       " 'young',\n",
       " 'cast',\n",
       " 'clothes',\n",
       " 'hip',\n",
       " 'soundtrack',\n",
       " 'appears',\n",
       " 'geared',\n",
       " 'towards',\n",
       " 'teenage',\n",
       " 'mindset',\n",
       " 'r',\n",
       " 'rating',\n",
       " 'content',\n",
       " 'justify',\n",
       " 'juvenile',\n",
       " 'older',\n",
       " 'information',\n",
       " 'literally',\n",
       " 'spoon',\n",
       " 'hard',\n",
       " 'instead',\n",
       " 'telling',\n",
       " 'dialogue',\n",
       " 'poorly',\n",
       " 'written',\n",
       " 'extremely',\n",
       " 'predictable',\n",
       " 'progresses',\n",
       " 'won',\n",
       " 'care',\n",
       " 'heroes',\n",
       " 'any',\n",
       " 'jeopardy',\n",
       " 'll',\n",
       " 'aren',\n",
       " 'basing',\n",
       " 'nobody',\n",
       " 'remembers',\n",
       " 'questionable',\n",
       " 'wisdom',\n",
       " 'especially',\n",
       " 'considers',\n",
       " 'target',\n",
       " 'fact',\n",
       " 'number',\n",
       " 'memorable',\n",
       " 'can',\n",
       " 'counted',\n",
       " 'hand',\n",
       " 'missing',\n",
       " 'finger',\n",
       " 'times',\n",
       " 'checked',\n",
       " 'six',\n",
       " 'clear',\n",
       " 'indication',\n",
       " 'them',\n",
       " 'than',\n",
       " 'cash',\n",
       " 'spending',\n",
       " 'dollar',\n",
       " 'judging',\n",
       " 'rash',\n",
       " 'awful',\n",
       " 'seeing',\n",
       " 'avoid',\n",
       " 'at',\n",
       " 'costs',\n",
       " 'quest',\n",
       " 'camelot',\n",
       " 'warner',\n",
       " 'bros',\n",
       " 'feature',\n",
       " 'length',\n",
       " 'fully',\n",
       " 'animated',\n",
       " 'steal',\n",
       " 'clout',\n",
       " 'disney',\n",
       " 'cartoon',\n",
       " 'empire',\n",
       " 'mouse',\n",
       " 'reason',\n",
       " 'worried',\n",
       " 'other',\n",
       " 'recent',\n",
       " 'challenger',\n",
       " 'throne',\n",
       " 'last',\n",
       " 'fall',\n",
       " 'promising',\n",
       " 'flawed',\n",
       " '20th',\n",
       " 'century',\n",
       " 'fox',\n",
       " 'anastasia',\n",
       " 'hercules',\n",
       " 'lively',\n",
       " 'colorful',\n",
       " 'palate',\n",
       " 'had',\n",
       " 'beat',\n",
       " 'hands',\n",
       " 'crown',\n",
       " '1997',\n",
       " 'piece',\n",
       " 'animation',\n",
       " 'year',\n",
       " 'contest',\n",
       " 'arrival',\n",
       " 'magic',\n",
       " 'kingdom',\n",
       " 'mediocre',\n",
       " '--',\n",
       " 'd',\n",
       " 'pocahontas',\n",
       " 'those',\n",
       " 'keeping',\n",
       " 'score',\n",
       " 'nearly',\n",
       " 'dull',\n",
       " 'revolves',\n",
       " 'adventures',\n",
       " 'free',\n",
       " 'spirited',\n",
       " 'kayley',\n",
       " 'voiced',\n",
       " 'jessalyn',\n",
       " 'gilsig',\n",
       " 'early',\n",
       " 'daughter',\n",
       " 'belated',\n",
       " 'knight',\n",
       " 'king',\n",
       " 'arthur',\n",
       " 'round',\n",
       " 'table',\n",
       " 'dream',\n",
       " 'follow',\n",
       " 'father',\n",
       " 'footsteps',\n",
       " 'she',\n",
       " 'chance',\n",
       " 'evil',\n",
       " 'warlord',\n",
       " 'ruber',\n",
       " 'gary',\n",
       " 'oldman',\n",
       " 'ex',\n",
       " 'gone',\n",
       " 'steals',\n",
       " 'magical',\n",
       " 'sword',\n",
       " 'excalibur',\n",
       " 'accidentally',\n",
       " 'loses',\n",
       " 'dangerous',\n",
       " 'booby',\n",
       " 'trapped',\n",
       " 'forest',\n",
       " 'help',\n",
       " 'hunky',\n",
       " 'blind',\n",
       " 'timberland',\n",
       " 'dweller',\n",
       " 'garrett',\n",
       " 'carey',\n",
       " 'elwes',\n",
       " 'headed',\n",
       " 'dragon',\n",
       " 'eric',\n",
       " 'idle',\n",
       " 'rickles',\n",
       " 'arguing',\n",
       " 'itself',\n",
       " 'able',\n",
       " 'medieval',\n",
       " 'sexist',\n",
       " 'prove',\n",
       " 'fighter',\n",
       " 'side',\n",
       " 'pure',\n",
       " 'showmanship',\n",
       " 'essential',\n",
       " 'element',\n",
       " 'expected',\n",
       " 'climb',\n",
       " 'high',\n",
       " 'ranks',\n",
       " 'differentiates',\n",
       " 'something',\n",
       " 'saturday',\n",
       " 'morning',\n",
       " 'subpar',\n",
       " 'instantly',\n",
       " 'forgettable',\n",
       " 'songs',\n",
       " 'integrated',\n",
       " 'computerized',\n",
       " 'footage',\n",
       " 'compare',\n",
       " 'run',\n",
       " 'angry',\n",
       " 'ogre',\n",
       " 'herc',\n",
       " 'battle',\n",
       " 'hydra',\n",
       " 'rest',\n",
       " 'case',\n",
       " 'stink',\n",
       " 'none',\n",
       " 'remotely',\n",
       " 'interesting',\n",
       " 'race',\n",
       " 'bland',\n",
       " 'end',\n",
       " 'tie',\n",
       " 'win',\n",
       " 'comedy',\n",
       " 'shtick',\n",
       " 'awfully',\n",
       " 'cloying',\n",
       " 'least',\n",
       " 'signs',\n",
       " 'pulse',\n",
       " 'fans',\n",
       " \"-'\",\n",
       " '90s',\n",
       " 'tgif',\n",
       " 'will',\n",
       " 'thrilled',\n",
       " 'jaleel',\n",
       " 'urkel',\n",
       " 'white',\n",
       " 'bronson',\n",
       " 'balki',\n",
       " 'pinchot',\n",
       " 'sharing',\n",
       " 'nicely',\n",
       " 'realized',\n",
       " 'though',\n",
       " 'm',\n",
       " 'loss',\n",
       " 'recall',\n",
       " 'specific',\n",
       " 'providing',\n",
       " 'voice',\n",
       " 'talent',\n",
       " 'enthusiastic',\n",
       " 'paired',\n",
       " 'singers',\n",
       " 'sound',\n",
       " 'musical',\n",
       " 'moments',\n",
       " 'jane',\n",
       " 'seymour',\n",
       " 'celine',\n",
       " 'dion',\n",
       " 'must',\n",
       " 'strain',\n",
       " 'through',\n",
       " 'aside',\n",
       " 'children',\n",
       " 'probably',\n",
       " 'adults',\n",
       " 'grievous',\n",
       " 'error',\n",
       " 'lack',\n",
       " 'personality',\n",
       " 'learn',\n",
       " 'goes',\n",
       " 'synopsis',\n",
       " 'mentally',\n",
       " 'unstable',\n",
       " 'undergoing',\n",
       " 'psychotherapy',\n",
       " 'saves',\n",
       " 'boy',\n",
       " 'potentially',\n",
       " 'fatal',\n",
       " 'falls',\n",
       " 'love',\n",
       " 'mother',\n",
       " 'fledgling',\n",
       " 'restauranteur',\n",
       " 'unsuccessfully',\n",
       " 'attempting',\n",
       " 'gain',\n",
       " 'woman',\n",
       " 'favor',\n",
       " 'takes',\n",
       " 'pictures',\n",
       " 'kills',\n",
       " 'comments',\n",
       " 'stalked',\n",
       " 'yet',\n",
       " 'seemingly',\n",
       " 'endless',\n",
       " 'string',\n",
       " 'spurned',\n",
       " 'psychos',\n",
       " 'getting',\n",
       " 'revenge',\n",
       " 'type',\n",
       " 'stable',\n",
       " 'category',\n",
       " '1990s',\n",
       " 'industry',\n",
       " 'theatrical',\n",
       " 'direct',\n",
       " 'proliferation',\n",
       " 'may',\n",
       " 'due',\n",
       " 'typically',\n",
       " 'inexpensive',\n",
       " 'produce',\n",
       " 'special',\n",
       " 'effects',\n",
       " 'stars',\n",
       " 'serve',\n",
       " 'vehicles',\n",
       " 'nudity',\n",
       " 'allowing',\n",
       " 'frequent',\n",
       " 'night',\n",
       " 'cable',\n",
       " 'wavers',\n",
       " 'slightly',\n",
       " 'norm',\n",
       " 'respect',\n",
       " 'psycho',\n",
       " 'never',\n",
       " 'affair',\n",
       " 'contrary',\n",
       " 'rejected',\n",
       " 'rather',\n",
       " 'lover',\n",
       " 'wife',\n",
       " 'husband',\n",
       " 'entry',\n",
       " 'doomed',\n",
       " 'collect',\n",
       " 'dust',\n",
       " 'viewed',\n",
       " 'midnight',\n",
       " 'provide',\n",
       " 'suspense',\n",
       " 'sets',\n",
       " 'interspersed',\n",
       " 'opening',\n",
       " 'credits',\n",
       " 'instance',\n",
       " 'serious',\n",
       " 'sounding',\n",
       " 'narrator',\n",
       " 'spouts',\n",
       " 'statistics',\n",
       " 'stalkers',\n",
       " 'ponders',\n",
       " 'cause',\n",
       " 'stalk',\n",
       " 'implicitly',\n",
       " 'implied',\n",
       " 'men',\n",
       " 'shown',\n",
       " 'snapshot',\n",
       " 'actor',\n",
       " 'jay',\n",
       " 'underwood',\n",
       " 'states',\n",
       " 'daryl',\n",
       " 'gleason',\n",
       " 'stalker',\n",
       " 'brooke',\n",
       " 'daniels',\n",
       " 'meant',\n",
       " 'called',\n",
       " 'guesswork',\n",
       " 'required',\n",
       " 'proceeds',\n",
       " 'begins',\n",
       " 'obvious',\n",
       " 'sequence',\n",
       " 'contrived',\n",
       " 'quite',\n",
       " 'brings',\n",
       " 'victim',\n",
       " 'together',\n",
       " 'obsesses',\n",
       " 'follows',\n",
       " 'tries',\n",
       " 'woo',\n",
       " 'plans',\n",
       " 'become',\n",
       " 'desperate',\n",
       " 'elaborate',\n",
       " 'include',\n",
       " 'cliche',\n",
       " 'murdered',\n",
       " 'pet',\n",
       " 'require',\n",
       " 'found',\n",
       " 'exception',\n",
       " 'cat',\n",
       " 'shower',\n",
       " 'events',\n",
       " 'lead',\n",
       " 'inevitable',\n",
       " 'showdown',\n",
       " 'survives',\n",
       " 'invariably',\n",
       " 'conclusion',\n",
       " 'turkey',\n",
       " 'uniformly',\n",
       " 'adequate',\n",
       " 'anything',\n",
       " 'home',\n",
       " 'either',\n",
       " 'turns',\n",
       " 'toward',\n",
       " 'melodrama',\n",
       " 'overdoes',\n",
       " 'words',\n",
       " 'manages',\n",
       " 'creepy',\n",
       " 'pass',\n",
       " 'demands',\n",
       " 'maryam',\n",
       " 'abo',\n",
       " 'close',\n",
       " 'played',\n",
       " 'bond',\n",
       " 'chick',\n",
       " 'living',\n",
       " 'daylights',\n",
       " 'equally',\n",
       " 'title',\n",
       " 'ditzy',\n",
       " 'strong',\n",
       " 'independent',\n",
       " 'business',\n",
       " 'owner',\n",
       " 'needs',\n",
       " 'proceed',\n",
       " 'example',\n",
       " 'suspicions',\n",
       " 'ensure',\n",
       " 'use',\n",
       " 'excuse',\n",
       " 'decides',\n",
       " 'return',\n",
       " 'toolbox',\n",
       " 'left',\n",
       " 'place',\n",
       " 'house',\n",
       " 'leave',\n",
       " 'door',\n",
       " 'answers',\n",
       " 'opens',\n",
       " 'wanders',\n",
       " 'returns',\n",
       " 'enters',\n",
       " 'our',\n",
       " 'heroine',\n",
       " 'danger',\n",
       " 'somehow',\n",
       " 'parked',\n",
       " ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def features_extract(document):\n",
    "    words = set(document)\n",
    "    features_final = {}\n",
    "    for w in features:\n",
    "        features_final[w]=(w in words)\n",
    "    return features_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featuresets = [(features_extract(rev), category) for (rev, category) in document]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.shuffle(featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = featuresets[1:1800]\n",
    "test = featuresets[1800:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.classify import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NBmodel = nltk.NaiveBayesClassifier.train(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(NBmodel, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "final_words = open('final_pickle','wb')\n",
    "pickle.dump(NBmodel,final_words)\n",
    "final_words.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = open('final_pickle','rb')\n",
    "new = pickle.load(model)\n",
    "model.close()\n",
    "nltk.classify.accuracy(new,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Combining Algorithms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import logistic, SGDClassifier\n",
    "#from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB_model- Accuracy 0.835\n",
      "logit_model- Accuracy 0.825\n",
      "BN_model- Accuracy 0.795\n",
      "SGD_model- Accuracy 0.775\n"
     ]
    }
   ],
   "source": [
    "MNB = SklearnClassifier(MultinomialNB())\n",
    "MNB_model = MNB.train(train)\n",
    "print(\"MNB_model- Accuracy\",nltk.classify.accuracy(MNB_model,test))\n",
    "logit = SklearnClassifier(logistic.LogisticRegression())\n",
    "logit_model = logit.train(train)\n",
    "print(\"logit_model- Accuracy\",nltk.classify.accuracy(logit_model,test))\n",
    "Ber = SklearnClassifier(BernoulliNB())\n",
    "BN_model = Ber.train(train)\n",
    "print(\"BN_model- Accuracy\",nltk.classify.accuracy(BN_model,test))\n",
    "SGD = SklearnClassifier(SGDClassifier())\n",
    "SGD_model = SGD.train(train)\n",
    "print(\"SGD_model- Accuracy\",nltk.classify.accuracy(SGD_model,test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(classifier,features):\n",
    "    voted = []\n",
    "    for c in classifier:\n",
    "        vote = c.classify(features)\n",
    "        voted.append(vote)\n",
    "    return mode(voted)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = [MNB_model,logit_model,BN_model,SGD_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(classifier,test[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class votedclassifier(ClassifierI):\n",
    "    def __init__(self,*classifier):\n",
    "        self.classifier = classifier\n",
    "        \n",
    "    def classify(self,features):\n",
    "        voted = []\n",
    "        for c in self.classifier:\n",
    "            vote = c.classify(features)\n",
    "            voted.append(vote)\n",
    "        return mode(voted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier_vote = votedclassifier(MNB_model,logit_model,BN_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.votedclassifier at 0x1ef770cddd8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New accuracy 0.83\n"
     ]
    }
   ],
   "source": [
    "print(\"New accuracy\",nltk.classify.accuracy(classifier_vote,test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentiment(tweet):\n",
    "    features = features_extract(tweet)\n",
    "    return votedclassifier(MNB_model,logit_model,BN_model).classify(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Sentiment from Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Twitter Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tweepy import Stream\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ckey= '7JzpvzEkgIXygwHZNDlHtbyul'\n",
    "csecret = 'WIbSoJPACDhDlNn2ekrLDO1ikeWzwAh5OFT8V7BavCLkkMVPJM'\n",
    "atoken = '915301601987919872-ihW5x7SV8dMW5lAG0nbyi69YfnmqQQl'\n",
    "asecret = 'xfz573YVAzIdSbMSlF5ffxLhzp6laG11vCfgCUoyWiRLd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auth = OAuthHandler(ckey,csecret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auth.set_access_token(atoken,asecret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Streamtweets = Stream(auth,StreamListener())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Streamtweets.filter(track = [\"Deloitte\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class mylistener(StreamListener):\n",
    "    def on_data(self, raw_data):\n",
    "        tweet = raw_data.split(',\"text\":\"')[1].split('\",\"source\":\"')[0]\n",
    "        sent_data = open('senti_data.txt','a')\n",
    "        sent_data.write(sentiment(tweet))\n",
    "        sent_data.close()\n",
    "#         save_data = open('deloitte_tweets.csv','a')\n",
    "#         new_data = open('deloitte_clean.csv','a')\n",
    "#         new_data.write(tweet)\n",
    "#         new_data.close()\n",
    "#         save_data.write(raw_data)\n",
    "#         save_data.write('\\n')\n",
    "#         save_data.close()\n",
    "        #print(raw_data)\n",
    "        return True\n",
    "    def on_error(self, status):\n",
    "        print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Streamtweets = Stream(auth,mylistener())\n",
    "Streamtweets.filter(track = [\"Deloitte\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
